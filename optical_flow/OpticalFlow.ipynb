{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "from torchvision.io import read_video\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(520, 960)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        return list_of_flows[-1][0]\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        return list_of_flows[-1][0]\n",
    "\n",
    "    def demo_optical_flow_dots(self, from_image, to_image, num_dots=50):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        \n",
    "        # Resize the predicted flow to match the original image size\n",
    "        height, width = from_image.size\n",
    "        predicted_flow = T.Resize((height, width))(predicted_flow.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        # Generate random dot coordinates\n",
    "        dots_x = np.random.randint(0, width, num_dots)\n",
    "        dots_y = np.random.randint(0, height, num_dots)\n",
    "        \n",
    "        # Draw dots on the from_image\n",
    "        from_image_with_dots = from_image.copy()\n",
    "        draw = ImageDraw.Draw(from_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "        \n",
    "        # Warp the dots to the to_image based on the predicted flow\n",
    "        to_image_with_dots = to_image.copy()\n",
    "        draw = ImageDraw.Draw(to_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            flow_x = predicted_flow[0, y, x].item()\n",
    "            flow_y = predicted_flow[1, y, x].item()\n",
    "            warped_x = x + flow_x\n",
    "            warped_y = y + flow_y\n",
    "            draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image_with_dots)\n",
    "        ax1.set_title(\"Input Image with Dots\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(to_image_with_dots)\n",
    "        ax2.set_title(\"Output Image with Warped Dots\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage example\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "optical_flow = RaftOpticalFlow(device)\n",
    "\n",
    "# Load video\n",
    "video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "_ = urlretrieve(video_url, video_path)\n",
    "\n",
    "frames, _, _ = read_video(str(video_path))\n",
    "frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "# Select two frames\n",
    "img1 = frames[100]\n",
    "img2 = frames[101]\n",
    "\n",
    "# Convert frames to PIL images\n",
    "img1 = T.ToPILImage()(img1)\n",
    "img2 = T.ToPILImage()(img2)\n",
    "\n",
    "optical_flow.demo_optical_flow_dots(img1, img2, num_dots=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "from torchvision.io import read_video\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import rp\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from icecream import ic\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image):\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(520, 960)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        return list_of_flows[-1][0]\n",
    "\n",
    "    def demo_optical_flow(self, from_image, to_image):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        flow_img = flow_to_image(predicted_flow)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image)\n",
    "        ax1.set_title(\"Input Image\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(flow_img.permute(1, 2, 0).cpu().numpy())\n",
    "        ax2.set_title(\"Predicted Optical Flow\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demo_optical_flow_dots(self, from_image, to_image, num_dots=50):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        \n",
    "        # Generate random dot coordinates\n",
    "        height, width = from_image.size\n",
    "        dots_x = np.random.randint(0, width, num_dots)\n",
    "        dots_y = np.random.randint(0, height, num_dots)\n",
    "        \n",
    "        # Draw dots on the from_image\n",
    "        from_image_with_dots = from_image.copy()\n",
    "        draw = ImageDraw.Draw(from_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "        \n",
    "        # Warp the dots to the to_image based on the predicted flow\n",
    "        to_image_with_dots = to_image.copy()\n",
    "        draw = ImageDraw.Draw(to_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            flow_x = predicted_flow[0, y, x].item()\n",
    "            flow_y = predicted_flow[1, y, x].item()\n",
    "            warped_x = x + flow_x\n",
    "            warped_y = y + flow_y\n",
    "            draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image_with_dots)\n",
    "        ax1.set_title(\"Input Image with Dots\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(to_image_with_dots)\n",
    "        ax2.set_title(\"Output Image with Warped Dots\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        return list_of_flows[-1][0]\n",
    "\n",
    "    def demo_optical_flow_dots(self, from_image, to_image, num_dots=50):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        \n",
    "        # Resize the predicted flow to match the original image size\n",
    "        height, width = from_image.size\n",
    "        predicted_flow = T.Resize((height, width))(predicted_flow.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        # Generate random dot coordinates\n",
    "        dots_x = np.random.randint(0, width, num_dots)\n",
    "        dots_y = np.random.randint(0, height, num_dots)\n",
    "        \n",
    "        # Draw dots on the from_image\n",
    "        from_image_with_dots = from_image.copy()\n",
    "        draw = ImageDraw.Draw(from_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "        \n",
    "        # Warp the dots to the to_image based on the predicted flow\n",
    "        to_image_with_dots = to_image.copy()\n",
    "        draw = ImageDraw.Draw(to_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            flow_x = predicted_flow[0, y, x].item()\n",
    "            flow_y = predicted_flow[1, y, x].item()\n",
    "            warped_x = x + flow_x\n",
    "            warped_y = y + flow_y\n",
    "            draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image_with_dots)\n",
    "        ax1.set_title(\"Input Image with Dots\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(to_image_with_dots)\n",
    "        ax2.set_title(\"Output Image with Warped Dots\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage example\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "optical_flow = RaftOpticalFlow(device)\n",
    "\n",
    "# Load video\n",
    "video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "_ = urlretrieve(video_url, video_path)\n",
    "\n",
    "frames, _, _ = read_video(str(video_path))\n",
    "frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "# Select two frames\n",
    "img1 = frames[100]\n",
    "img2 = frames[101]\n",
    "\n",
    "# Convert frames to PIL images\n",
    "img1 = T.ToPILImage()(img1)\n",
    "img2 = T.ToPILImage()(img2)\n",
    "\n",
    "optical_flow.demo_optical_flow(img1, img2)\n",
    "optical_flow.demo_optical_flow_dots(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flow = optical_flow.get_optical_flow(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_flow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "rp.as_numpy_image(img1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "from torchvision.io import read_video\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image, multiple_of=8):\n",
    "        # Ensure image dimensions are divisible by `multiple_of`\n",
    "        width, height = image.size\n",
    "        new_height = (height // multiple_of) * multiple_of\n",
    "        new_width = (width // multiple_of) * multiple_of\n",
    "\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(new_height, new_width)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        assert from_image.size == to_image.size, \"Input images must have the same size\"\n",
    "\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        output_flow = list_of_flows[-1][0]\n",
    "\n",
    "        # Resize the predicted flow back to the original image size\n",
    "        width, height = from_image.size\n",
    "        output_flow = T.Resize((height, width))(output_flow.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        return output_flow\n",
    "\n",
    "    def demo_optical_flow(self, from_image, to_image):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        flow_img = flow_to_image(predicted_flow)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image)\n",
    "        ax1.set_title(\"Input Image\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(flow_img.permute(1, 2, 0).cpu().numpy())\n",
    "        ax2.set_title(\"Predicted Optical Flow\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demo_optical_flow_dots(self, from_image, to_image, num_dots=50):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        \n",
    "        # Generate random dot coordinates\n",
    "        width, height = from_image.size\n",
    "        dots_x = np.random.randint(0, width, num_dots)\n",
    "        dots_y = np.random.randint(0, height, num_dots)\n",
    "        \n",
    "        # Draw dots on the from_image\n",
    "        from_image_with_dots = from_image.copy()\n",
    "        draw = ImageDraw.Draw(from_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "        \n",
    "        # Warp the dots to the to_image based on the predicted flow\n",
    "        to_image_with_dots = to_image.copy()\n",
    "        draw = ImageDraw.Draw(to_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            flow_x = predicted_flow[0, y, x].item()\n",
    "            flow_y = predicted_flow[1, y, x].item()\n",
    "            warped_x = x + flow_x\n",
    "            warped_y = y + flow_y\n",
    "            draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image_with_dots)\n",
    "        ax1.set_title(\"Input Image with Dots\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(to_image_with_dots)\n",
    "        ax2.set_title(\"Output Image with Warped Dots\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Usage example\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if not 'optical_flow' in vars():\n",
    "    optical_flow = RaftOpticalFlow(device)\n",
    "\n",
    "# Load video\n",
    "video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "_ = urlretrieve(video_url, video_path)\n",
    "\n",
    "frames, _, _ = read_video(str(video_path))\n",
    "frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "# Select two frames\n",
    "img1 = frames[100]\n",
    "img2 = frames[110]\n",
    "\n",
    "# Convert frames to PIL images\n",
    "img1 = T.ToPILImage()(img1)\n",
    "img2 = T.ToPILImage()(img2)\n",
    "\n",
    "optical_flow.demo_optical_flow(img1, img2)\n",
    "optical_flow.demo_optical_flow_dots(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from icecream import ic\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.io import read_video\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image, multiple_of=8):\n",
    "        # Ensure image dimensions are divisible by `multiple_of`\n",
    "        width, height = image.size\n",
    "        new_height = (height // multiple_of) * multiple_of\n",
    "        new_width = (width // multiple_of) * multiple_of\n",
    "\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(new_height, new_width)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        assert from_image.size == to_image.size, \"Input images must have the same size\"\n",
    "\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        output_flow = list_of_flows[-1][0]\n",
    "\n",
    "        # Resize the predicted flow back to the original image size\n",
    "        width, height = from_image.size\n",
    "        output_flow = T.Resize((height, width))(output_flow.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        return output_flow\n",
    "\n",
    "    def demo_optical_flow(self, from_image, to_image):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        flow_img = flow_to_image(predicted_flow)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image)\n",
    "        ax1.set_title(\"Input Image\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(flow_img.permute(1, 2, 0).cpu().numpy())\n",
    "        ax2.set_title(\"Predicted Optical Flow\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demo_optical_flow_dots(self, from_image, to_image, num_rows=10, num_cols=10):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        \n",
    "        width, height = from_image.size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "        \n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = dots_x.flatten()\n",
    "        dots_y = dots_y.flatten()\n",
    "        \n",
    "        # Draw dots on the from_image\n",
    "        from_image_with_dots = from_image.copy()\n",
    "        draw = ImageDraw.Draw(from_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "        \n",
    "        # Warp the dots to the to_image based on the predicted flow\n",
    "        to_image_with_dots = to_image.copy()\n",
    "        draw = ImageDraw.Draw(to_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            flow_x = predicted_flow[0, y, x].item()\n",
    "            flow_y = predicted_flow[1, y, x].item()\n",
    "            warped_x = x + flow_x\n",
    "            warped_y = y + flow_y\n",
    "            draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image_with_dots)\n",
    "        ax1.set_title(\"Input Image with Dots\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(to_image_with_dots)\n",
    "        ax2.set_title(\"Output Image with Warped Dots\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def demo_optical_flow_animation(self, frames, num_rows=10, num_cols=10):\n",
    "        width, height = frames[0].size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "        \n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = dots_x.flatten()\n",
    "        dots_y = dots_y.flatten()\n",
    "        \n",
    "        animation_frames = []\n",
    "        \n",
    "        for frame_idx in range(len(frames) - 1):\n",
    "            from_image = frames[frame_idx]\n",
    "            to_image = frames[frame_idx + 1]\n",
    "            \n",
    "            predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "            \n",
    "            # Draw dots on the from_image\n",
    "            from_image_with_dots = from_image.copy()\n",
    "            draw = ImageDraw.Draw(from_image_with_dots)\n",
    "            for x, y in zip(dots_x, dots_y):\n",
    "                draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "            \n",
    "            # Warp the dots to the to_image based on the predicted flow\n",
    "            for x, y in zip(dots_x, dots_y):\n",
    "                flow_x = predicted_flow[0, y, x].item()\n",
    "                flow_y = predicted_flow[1, y, x].item()\n",
    "                warped_x = x + flow_x\n",
    "                warped_y = y + flow_y\n",
    "                draw.line([(x, y), (warped_x, warped_y)], fill=\"blue\", width=1)\n",
    "                draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "            \n",
    "            animation_frames.append(from_image_with_dots)\n",
    "        \n",
    "        rp.display_image_slideshow(animation_frames)\n",
    "\n",
    "# Usage example\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "optical_flow = RaftOpticalFlow(device)\n",
    "\n",
    "# Load video\n",
    "video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "_ = urlretrieve(video_url, video_path)\n",
    "\n",
    "frames, _, _ = read_video(str(video_path))\n",
    "frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "# Convert frames to PIL images\n",
    "pil_frames = [T.ToPILImage()(frame) for frame in frames]\n",
    "\n",
    "# Demo optical flow with dots\n",
    "optical_flow.demo_optical_flow_dots(pil_frames[100], pil_frames[110], num_rows=20, num_cols=30)\n",
    "\n",
    "# Demo optical flow animation\n",
    "optical_flow.demo_optical_flow_animation(pil_frames[100:120], num_rows=20, num_cols=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from icecream import ic\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.io import read_video\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "from torchvision.io import read_video\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rp\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image, multiple_of=8):\n",
    "        # Ensure image dimensions are divisible by `multiple_of`\n",
    "        width, height = image.size\n",
    "        new_height = (height // multiple_of) * multiple_of\n",
    "        new_width = (width // multiple_of) * multiple_of\n",
    "\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(new_height, new_width)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        assert from_image.size == to_image.size, \"Input images must have the same size\"\n",
    "\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        output_flow = list_of_flows[-1][0]\n",
    "\n",
    "        # Resize the predicted flow back to the original image size\n",
    "        width, height = from_image.size\n",
    "        output_flow = T.Resize((height, width))(output_flow.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        return output_flow\n",
    "\n",
    "    def demo_optical_flow(self, from_image, to_image):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        flow_img = flow_to_image(predicted_flow)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image)\n",
    "        ax1.set_title(\"Input Image\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(flow_img.permute(1, 2, 0).cpu().numpy())\n",
    "        ax2.set_title(\"Predicted Optical Flow\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demo_optical_flow_dots(self, from_image, to_image, num_rows=10, num_cols=10):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        \n",
    "        width, height = from_image.size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "        \n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = dots_x.flatten()\n",
    "        dots_y = dots_y.flatten()\n",
    "        \n",
    "        # Draw dots on the from_image\n",
    "        from_image_with_dots = from_image.copy()\n",
    "        draw = ImageDraw.Draw(from_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "        \n",
    "        # Warp the dots to the to_image based on the predicted flow\n",
    "        to_image_with_dots = to_image.copy()\n",
    "        draw = ImageDraw.Draw(to_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            flow_x = predicted_flow[0, y, x].item()\n",
    "            flow_y = predicted_flow[1, y, x].item()\n",
    "            warped_x = x + flow_x\n",
    "            warped_y = y + flow_y\n",
    "            draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image_with_dots)\n",
    "        ax1.set_title(\"Input Image with Dots\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(to_image_with_dots)\n",
    "        ax2.set_title(\"Output Image with Warped Dots\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def query_optical_flow(self, coordinates, flow_map):\n",
    "        # print(\"Coordinates shape:\", coordinates.shape)\n",
    "        # print(\"Flow map shape:\", flow_map.shape)\n",
    "        \n",
    "        # Normalize coordinates to [-1, 1] range\n",
    "        height, width = flow_map.shape[1:]\n",
    "        normalized_coordinates = coordinates.clone()\n",
    "        normalized_coordinates[0] = (coordinates[0] / (width - 1)) * 2 - 1\n",
    "        normalized_coordinates[1] = (coordinates[1] / (height - 1)) * 2 - 1\n",
    "        normalized_coordinates = normalized_coordinates.permute(1, 0).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # print(\"Normalized coordinates shape:\", normalized_coordinates.shape)\n",
    "        \n",
    "        # Perform bilinear interpolation using grid_sample\n",
    "        flow_map_permuted = flow_map.unsqueeze(0)\n",
    "        # print(\"Flow map permuted shape:\", flow_map_permuted.shape)\n",
    "        \n",
    "        deltas = torch.nn.functional.grid_sample(flow_map_permuted, normalized_coordinates, mode='bilinear', align_corners=True)\n",
    "        # print(\"Deltas shape after grid_sample:\", deltas.shape)\n",
    "        \n",
    "        # deltas = deltas.squeeze(0).permute(1, 0)\n",
    "        deltas = deltas.squeeze(0).squeeze(1).permute(1, 0).T\n",
    "        # print(\"Deltas shape after squeeze and permute:\", deltas.shape)\n",
    "        \n",
    "        return deltas\n",
    "    def add_optical_flow(self, coordinates, flow_map):\n",
    "        deltas = self.query_optical_flow(coordinates, flow_map)\n",
    "        return coordinates + deltas\n",
    "\n",
    "    def demo_optical_flow_animation(self, frames, num_rows=100, num_cols=100):\n",
    "        width, height = frames[0].size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "        \n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = torch.from_numpy(dots_x.flatten()).float().to(self.device)\n",
    "        dots_y = torch.from_numpy(dots_y.flatten()).float().to(self.device)\n",
    "        \n",
    "        coordinates = torch.stack([dots_x, dots_y])\n",
    "        \n",
    "        animation_frames = []\n",
    "        \n",
    "        for frame_idx in tqdm(range(len(frames) - 1)):\n",
    "            from_image = frames[frame_idx]\n",
    "            to_image = frames[frame_idx + 1]\n",
    "            \n",
    "            predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "            \n",
    "            # Update dot positions by accumulating optical flows\n",
    "            coordinates = self.add_optical_flow(coordinates, predicted_flow)\n",
    "            \n",
    "            # Convert PIL image to OpenCV format\n",
    "            from_image_cv = cv2.cvtColor(np.array(from_image), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Draw dots on the from_image using OpenCV\n",
    "            dot_positions = coordinates.cpu().numpy().T\n",
    "            dot_positions = dot_positions[~np.isnan(dot_positions).any(axis=1)]  # Remove NaN values\n",
    "            dot_positions = dot_positions.astype(np.int32)\n",
    "            from_image_cv[dot_positions[:, 1], dot_positions[:, 0]] = (0, 0, 255)  # Draw red dots\n",
    "            \n",
    "            # Convert the OpenCV image back to PIL format\n",
    "            from_image_with_dots = Image.fromarray(cv2.cvtColor(from_image_cv, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            animation_frames.append(from_image_with_dots)\n",
    "        \n",
    "        rp.display_image_slideshow(animation_frames)\n",
    "\n",
    "def demo_flow_anim():\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Usage example\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        optical_flow = RaftOpticalFlow(device)\n",
    "        \n",
    "        # Load video\n",
    "        video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "        video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "        _ = urlretrieve(video_url, video_path)\n",
    "        \n",
    "        frames, _, _ = read_video(str(video_path))\n",
    "        frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "        \n",
    "        # Convert frames to PIL images\n",
    "        pil_frames = [T.ToPILImage()(frame) for frame in frames]\n",
    "        \n",
    "        # Demo optical flow with dots\n",
    "        optical_flow.demo_optical_flow_dots(pil_frames[100], pil_frames[110], num_rows=20, num_cols=30)\n",
    "        \n",
    "        # Demo optical flow animation\n",
    "        optical_flow.demo_optical_flow_animation(pil_frames[100:200], num_rows=20, num_cols=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from einops import rearrange\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.io import read_video\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image, multiple_of=8):\n",
    "        # Ensure image dimensions are divisible by `multiple_of`\n",
    "        width, height = image.size\n",
    "        new_height = (height // multiple_of) * multiple_of\n",
    "        new_width = (width // multiple_of) * multiple_of\n",
    "\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(new_height, new_width)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        assert from_image.size == to_image.size, \"Input images must have the same size\"\n",
    "\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        output_flow = list_of_flows[-1][0]\n",
    "\n",
    "        # Resize the predicted flow back to the original image size\n",
    "        width, height = from_image.size\n",
    "        output_flow = T.Resize((height, width))(output_flow.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        return output_flow\n",
    "\n",
    "    def query_optical_flow(self, coordinates, flow_map):\n",
    "        print(\"Coordinates shape:\", coordinates.shape)\n",
    "        print(\"Flow map shape:\", flow_map.shape)\n",
    "        \n",
    "        # Normalize coordinates to [-1, 1] range\n",
    "        height, width = flow_map.shape[1:]\n",
    "        normalized_coordinates = coordinates.clone()\n",
    "        normalized_coordinates[0] = (coordinates[0] / (width - 1)) * 2 - 1\n",
    "        normalized_coordinates[1] = (coordinates[1] / (height - 1)) * 2 - 1\n",
    "        normalized_coordinates = rearrange(normalized_coordinates, 'c n -> () () n c')\n",
    "        \n",
    "        print(\"Normalized coordinates shape:\", normalized_coordinates.shape)\n",
    "        \n",
    "        # Perform bilinear interpolation using grid_sample\n",
    "        flow_map_permuted = rearrange(flow_map, 'c h w -> () c h w')\n",
    "        print(\"Flow map permuted shape:\", flow_map_permuted.shape)\n",
    "        \n",
    "        deltas = torch.nn.functional.grid_sample(flow_map_permuted, normalized_coordinates, mode='bilinear', align_corners=True)\n",
    "        print(\"Deltas shape after grid_sample:\", deltas.shape)\n",
    "        \n",
    "        deltas = rearrange(deltas, '() c () n -> n c')\n",
    "        print(\"Deltas shape after rearrange:\", deltas.shape)\n",
    "        \n",
    "        return deltas\n",
    "\n",
    "    def add_optical_flow(self, coordinates, flow_map):\n",
    "        deltas = self.query_optical_flow(coordinates, flow_map)\n",
    "        return coordinates + deltas\n",
    "\n",
    "    def demo_optical_flow_animation(self, frames, num_rows=10, num_cols=10):\n",
    "        width, height = frames[0].size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "        \n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = torch.from_numpy(dots_x.flatten()).float().to(self.device)\n",
    "        dots_y = torch.from_numpy(dots_y.flatten()).float().to(self.device)\n",
    "        \n",
    "        coordinates = torch.stack([dots_x, dots_y])\n",
    "        \n",
    "        animation_frames = []\n",
    "        \n",
    "        for frame_idx in range(len(frames) - 1):\n",
    "            from_image = frames[frame_idx]\n",
    "            to_image = frames[frame_idx + 1]\n",
    "            \n",
    "            predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "            \n",
    "            # Update dot positions by accumulating optical flows\n",
    "            coordinates = self.add_optical_flow(coordinates, predicted_flow)\n",
    "            \n",
    "            # Draw dots on the from_image\n",
    "            from_image_with_dots = from_image.copy()\n",
    "            draw = ImageDraw.Draw(from_image_with_dots)\n",
    "            for x, y in zip(coordinates[0], coordinates[1]):\n",
    "                if not (torch.isnan(x) or torch.isnan(y)):\n",
    "                    draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "            \n",
    "            animation_frames.append(from_image_with_dots)\n",
    "        \n",
    "        rp.display_image_slideshow(animation_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def demo_flow_anim():\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Usage example\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        optical_flow = RaftOpticalFlow(device)\n",
    "        \n",
    "        # Load video\n",
    "        video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "        video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "        _ = urlretrieve(video_url, video_path)\n",
    "        \n",
    "        frames, _, _ = read_video(str(video_path))\n",
    "        frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "        \n",
    "        # Convert frames to PIL images\n",
    "        pil_frames = [T.ToPILImage()(frame) for frame in frames]\n",
    "        \n",
    "        # Demo optical flow with dots\n",
    "        optical_flow.demo_optical_flow_dots(pil_frames[100], pil_frames[110], num_rows=20, num_cols=30)\n",
    "        \n",
    "        # Demo optical flow animation\n",
    "        optical_flow.demo_optical_flow_animation(pil_frames[100:200], num_rows=200, num_cols=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_flow_anim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from icecream import ic\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.io import read_video\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image, multiple_of=8):\n",
    "        # Ensure image dimensions are divisible by `multiple_of`\n",
    "        width, height = image.size\n",
    "        new_height = (height // multiple_of) * multiple_of\n",
    "        new_width = (width // multiple_of) * multiple_of\n",
    "\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(new_height, new_width)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        assert from_image.size == to_image.size, \"Input images must have the same size\"\n",
    "\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        output_flow = list_of_flows[-1][0]\n",
    "\n",
    "        # Resize the predicted flow back to the original image size\n",
    "        width, height = from_image.size\n",
    "        output_flow = T.Resize((height, width))(output_flow.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        return output_flow\n",
    "\n",
    "    def query_optical_flow(self, coordinates, flow_map):\n",
    "        # Normalize coordinates to [-1, 1] range\n",
    "        height, width = flow_map.shape[1:]\n",
    "        normalized_coordinates = coordinates.clone()\n",
    "        normalized_coordinates[0] = (coordinates[0] / (width - 1)) * 2 - 1\n",
    "        normalized_coordinates[1] = (coordinates[1] / (height - 1)) * 2 - 1\n",
    "        normalized_coordinates = normalized_coordinates.permute(1, 0).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Perform bilinear interpolation using grid_sample\n",
    "        flow_map_permuted = flow_map.unsqueeze(0)\n",
    "\n",
    "        deltas = torch.nn.functional.grid_sample(flow_map_permuted, normalized_coordinates, mode='bilinear', align_corners=True)\n",
    "        deltas = deltas.squeeze(0).squeeze(1).permute(1, 0).T\n",
    "\n",
    "        return deltas\n",
    "\n",
    "    def add_optical_flow(self, coordinates, flow_map):\n",
    "        deltas = self.query_optical_flow(coordinates, flow_map)\n",
    "        return coordinates + deltas\n",
    "\n",
    "    def demo_optical_flow_animation(self, frames, num_rows=100, num_cols=100):\n",
    "        width, height = frames[0].size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "\n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = torch.from_numpy(dots_x.flatten()).float().to(self.device)\n",
    "        dots_y = torch.from_numpy(dots_y.flatten()).float().to(self.device)\n",
    "\n",
    "        coordinates = torch.stack([dots_x, dots_y])\n",
    "\n",
    "        animation_frames = []\n",
    "\n",
    "        for frame_idx in tqdm(range(len(frames) - 1)):\n",
    "            from_image = frames[frame_idx]\n",
    "            to_image = frames[frame_idx + 1]\n",
    "\n",
    "            predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "\n",
    "            # Update dot positions by accumulating optical flows\n",
    "            coordinates = self.add_optical_flow(coordinates, predicted_flow)\n",
    "\n",
    "            # Draw dots on the from_image\n",
    "            from_image_with_dots = from_image.copy()\n",
    "            draw = ImageDraw.Draw(from_image_with_dots)\n",
    "            for x, y in zip(coordinates[0], coordinates[1]):\n",
    "                if not (torch.isnan(x) or torch.isnan(y)):\n",
    "                    draw.ellipse((x-1, y-1, x+1, y+1), fill=\"red\")\n",
    "\n",
    "            animation_frames.append(from_image_with_dots)\n",
    "\n",
    "        rp.display_image_slideshow(animation_frames)\n",
    "\n",
    "# Usage example\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "optical_flow = RaftOpticalFlow(device)\n",
    "\n",
    "# Load video\n",
    "video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "_ = urlretrieve(video_url, video_path)\n",
    "\n",
    "frames, _, _ = read_video(str(video_path))\n",
    "frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "\n",
    "# Convert frames to PIL images\n",
    "pil_frames = [T.ToPILImage()(frame) for frame in frames]\n",
    "\n",
    "# Demo optical flow animation\n",
    "optical_flow.demo_optical_flow_animation(pil_frames[100:200], num_rows=200, num_cols=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rp\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from icecream import ic\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision.io import read_video\n",
    "from torchvision.models.optical_flow import raft_large\n",
    "from torchvision.utils import flow_to_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class RaftOpticalFlow:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.model = raft_large(pretrained=True, progress=False).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def preprocess(self, image, multiple_of=8):\n",
    "        # Ensure image dimensions are divisible by `multiple_of`\n",
    "        width, height = image.size\n",
    "        new_height = (height // multiple_of) * multiple_of\n",
    "        new_width = (width // multiple_of) * multiple_of\n",
    "\n",
    "        transforms = T.Compose(\n",
    "            [\n",
    "                T.ToTensor(),\n",
    "                T.Normalize(mean=0.5, std=0.5),  # map [0, 1] into [-1, 1]\n",
    "                T.Resize(size=(new_height, new_width)),\n",
    "            ]\n",
    "        )\n",
    "        return transforms(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def get_optical_flow(self, from_image, to_image):\n",
    "        assert from_image.size == to_image.size, \"Input images must have the same size\"\n",
    "\n",
    "        img1 = self.preprocess(from_image)\n",
    "        img2 = self.preprocess(to_image)\n",
    "        list_of_flows = self.model(img1, img2)\n",
    "        output_flow = list_of_flows[-1][0]\n",
    "\n",
    "        # Resize the predicted flow back to the original image size\n",
    "        width, height = from_image.size\n",
    "        output_flow = T.Resize((height, width))(output_flow.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        return output_flow\n",
    "\n",
    "    def demo_optical_flow(self, from_image, to_image):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        flow_img = flow_to_image(predicted_flow)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image)\n",
    "        ax1.set_title(\"Input Image\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(flow_img.permute(1, 2, 0).cpu().numpy())\n",
    "        ax2.set_title(\"Predicted Optical Flow\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def demo_optical_flow_dots(self, from_image, to_image, num_rows=10, num_cols=10):\n",
    "        predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "        \n",
    "        width, height = from_image.size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "        \n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = dots_x.flatten()\n",
    "        dots_y = dots_y.flatten()\n",
    "        \n",
    "        # Draw dots on the from_image\n",
    "        from_image_with_dots = from_image.copy()\n",
    "        draw = ImageDraw.Draw(from_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            draw.ellipse((x-2, y-2, x+2, y+2), fill=\"red\")\n",
    "        \n",
    "        # Warp the dots to the to_image based on the predicted flow\n",
    "        to_image_with_dots = to_image.copy()\n",
    "        draw = ImageDraw.Draw(to_image_with_dots)\n",
    "        for x, y in zip(dots_x, dots_y):\n",
    "            flow_x = predicted_flow[0, y, x].item()\n",
    "            flow_y = predicted_flow[1, y, x].item()\n",
    "            warped_x = x + flow_x\n",
    "            warped_y = y + flow_y\n",
    "            draw.ellipse((warped_x-2, warped_y-2, warped_x+2, warped_y+2), fill=\"blue\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(from_image_with_dots)\n",
    "        ax1.set_title(\"Input Image with Dots\")\n",
    "        ax1.axis(\"off\")\n",
    "        ax2.imshow(to_image_with_dots)\n",
    "        ax2.set_title(\"Output Image with Warped Dots\")\n",
    "        ax2.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def query_optical_flow(self, coordinates, flow_map):\n",
    "        # print(\"Coordinates shape:\", coordinates.shape)\n",
    "        # print(\"Flow map shape:\", flow_map.shape)\n",
    "        \n",
    "        # Normalize coordinates to [-1, 1] range\n",
    "        height, width = flow_map.shape[1:]\n",
    "        normalized_coordinates = coordinates.clone()\n",
    "        normalized_coordinates[0] = (coordinates[0] / (width - 1)) * 2 - 1\n",
    "        normalized_coordinates[1] = (coordinates[1] / (height - 1)) * 2 - 1\n",
    "        normalized_coordinates = normalized_coordinates.permute(1, 0).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        # print(\"Normalized coordinates shape:\", normalized_coordinates.shape)\n",
    "        \n",
    "        # Perform bilinear interpolation using grid_sample\n",
    "        flow_map_permuted = flow_map.unsqueeze(0)\n",
    "        # print(\"Flow map permuted shape:\", flow_map_permuted.shape)\n",
    "        \n",
    "        deltas = torch.nn.functional.grid_sample(flow_map_permuted, normalized_coordinates, mode='bilinear', align_corners=True)\n",
    "        # print(\"Deltas shape after grid_sample:\", deltas.shape)\n",
    "        \n",
    "        # deltas = deltas.squeeze(0).permute(1, 0)\n",
    "        deltas = deltas.squeeze(0).squeeze(1).permute(1, 0).T\n",
    "        # print(\"Deltas shape after squeeze and permute:\", deltas.shape)\n",
    "        \n",
    "        return deltas\n",
    "    def add_optical_flow(self, coordinates, flow_map):\n",
    "        deltas = self.query_optical_flow(coordinates, flow_map)\n",
    "        return coordinates + deltas\n",
    "\n",
    "    def demo_optical_flow_animation(self, frames, num_rows=100, num_cols=100):\n",
    "        width, height = frames[0].size\n",
    "        x_step = width // (num_cols + 1)\n",
    "        y_step = height // (num_rows + 1)\n",
    "        \n",
    "        dots_x, dots_y = np.meshgrid(np.arange(x_step, width, x_step), np.arange(y_step, height, y_step))\n",
    "        dots_x = torch.from_numpy(dots_x.flatten()).float().to(self.device)\n",
    "        dots_y = torch.from_numpy(dots_y.flatten()).float().to(self.device)\n",
    "        \n",
    "        coordinates = torch.stack([dots_x, dots_y])\n",
    "        \n",
    "        animation_frames = []\n",
    "        \n",
    "        for frame_idx in tqdm(range(len(frames) - 1)):\n",
    "            from_image = frames[frame_idx]\n",
    "            to_image = frames[frame_idx + 1]\n",
    "            \n",
    "            predicted_flow = self.get_optical_flow(from_image, to_image)\n",
    "            \n",
    "            # Update dot positions by accumulating optical flows\n",
    "            coordinates = self.add_optical_flow(coordinates, predicted_flow)\n",
    "            \n",
    "            # Convert PIL image to OpenCV format\n",
    "            from_image_cv = cv2.cvtColor(np.array(from_image), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Draw dots on the from_image using OpenCV\n",
    "            dot_positions = coordinates.cpu().numpy().T\n",
    "            dot_positions = dot_positions[~np.isnan(dot_positions).any(axis=1)]  # Remove NaN values\n",
    "            dot_positions = dot_positions.astype(np.int32)\n",
    "            from_image_cv[\n",
    "                np.clip(dot_positions[:, 1], 0, from_image_cv.shape[0]-1),\n",
    "                np.clip(dot_positions[:, 0], 0, from_image_cv.shape[1]-1),\n",
    "            ] = (0, 0, 255)  # Draw red dots\n",
    "            \n",
    "            # Convert the OpenCV image back to PIL format\n",
    "            from_image_with_dots = Image.fromarray(cv2.cvtColor(from_image_cv, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            animation_frames.append(from_image_with_dots)\n",
    "        \n",
    "        rp.display_image_slideshow(animation_frames)\n",
    "\n",
    "\n",
    "def demo_flow_anim():\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Usage example\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        optical_flow = RaftOpticalFlow(device)\n",
    "        \n",
    "        # Load video\n",
    "        video_url = \"https://download.pytorch.org/tutorial/pexelscom_pavel_danilyuk_basketball_hd.mp4\"\n",
    "        video_path = Path(tempfile.mkdtemp()) / \"basketball.mp4\"\n",
    "        _ = urlretrieve(video_url, video_path)\n",
    "        \n",
    "        frames, _, _ = read_video(str(video_path))\n",
    "        frames = frames.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "        \n",
    "        # Convert frames to PIL images\n",
    "        pil_frames = [T.ToPILImage()(frame) for frame in frames]\n",
    "        \n",
    "        # Demo optical flow with dots\n",
    "        optical_flow.demo_optical_flow_dots(pil_frames[100], pil_frames[110], num_rows=20, num_cols=30)\n",
    "        \n",
    "        # Demo optical flow animation\n",
    "        optical_flow.demo_optical_flow_animation(pil_frames[100:200], num_rows=200, num_cols=300)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TODO:\n",
    "- Bulk operations: getting flows from a video tensor or iterable and returning a generator (lazy) or a tensor, with a show_progress\n",
    "- Einops all the way\n",
    "- Document each func and tensor shapes\n",
    "- backwards / forwards occlusion detection + demo\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_flow_anim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python vaetuner",
   "language": "python",
   "name": "vaetuner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
